{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import vstack\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "colums = df_train.columns.to_list()\n",
    "colums.remove('review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ac, neutral: 1814, positive: 51, negative: 417, negative_positive: 1, total: 2283\n",
      "Columns: air_panas, neutral: 1922, positive: 26, negative: 335, negative_positive: 0, total: 2283\n",
      "Columns: bau, neutral: 1911, positive: 12, negative: 360, negative_positive: 0, total: 2283\n",
      "Columns: general, neutral: 2023, positive: 230, negative: 30, negative_positive: 0, total: 2283\n",
      "Columns: kebersihan, neutral: 1350, positive: 205, negative: 722, negative_positive: 6, total: 2283\n",
      "Columns: linen, neutral: 1613, positive: 63, negative: 606, negative_positive: 1, total: 2283\n",
      "Columns: service, neutral: 1649, positive: 247, negative: 386, negative_positive: 1, total: 2283\n",
      "Columns: sunrise_meal, neutral: 2108, positive: 75, negative: 100, negative_positive: 0, total: 2283\n",
      "Columns: tv, neutral: 2075, positive: 13, negative: 195, negative_positive: 0, total: 2283\n",
      "Columns: wifi, neutral: 1928, positive: 25, negative: 330, negative_positive: 0, total: 2283\n"
     ]
    }
   ],
   "source": [
    "for col in colums:\n",
    "    count = df_train[col].value_counts()\n",
    "\n",
    "    if not \"neg_pos\" in count:\n",
    "        count['neg_pos'] = 0\n",
    "        \n",
    "    print(\"Columns: {}, neutral: {}, positive: {}, negative: {}, negative_positive: {}, total: {}\".format(col, count['neut'], count['pos'], count['neg'], count['neg_pos'], count.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(xtrain):\n",
    "    sentences = [word_tokenize(content.lower()) for content in xtrain]\n",
    "    vectorizer = FastText(sentences, vector_size=300, window=3, min_count=1, workers=4, epochs=1000, sg=0, hs=0)\n",
    "    vectorizer.save('model/test.ft')\n",
    "    print('fasttext model saved at model/test.ft')\n",
    "\n",
    "def norm_sent_vector(sentence, wv):\n",
    "    vecs = [wv[word.lower()] for word in word_tokenize(sentence)] \n",
    "    norm_vecs = [vec / np.linalg.norm(vecs) for vec in vecs if np.linalg.norm(vecs) > 0]\n",
    "    sent_vec = np.mean(norm_vecs, axis=0)\n",
    "    return sent_vec\n",
    "\n",
    "def hyperparam_tuning(xtrain, ytrain, xvalid, yvalid, classifier, param_grid):\n",
    "    # combine train and valid\n",
    "    x = vstack([xtrain, xvalid])\n",
    "    y = ytrain + yvalid\n",
    "    \n",
    "    # create predefined split\n",
    "    # -1 for all training and 0 for all validation\n",
    "    ps = PredefinedSplit([-1] * len(ytrain) + [0] * len(yvalid))\n",
    "    clf = GridSearchCV(classifier, param_grid, cv = ps)\n",
    "    clf = clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "def train_and_test(feature=\"bow\", classifier=\"nb\", aspect=\"ac\", ft_path='model/test.ft'):\n",
    "    xtrain = pd.read_csv('dataset/train_preprocess.csv')['review']\n",
    "    xvalid = pd.read_csv('dataset/valid_preprocess.csv')['review']\n",
    "    xtest = pd.read_csv('dataset/test_preprocess.csv')['review']\n",
    "\n",
    "    # label_encoder = LabelEncoder()\n",
    "    ytrain = list(pd.read_csv('dataset/train_preprocess.csv')[aspect])\n",
    "    yvalid = list(pd.read_csv('dataset/valid_preprocess.csv')[aspect])\n",
    "    ytest = list(pd.read_csv('dataset/test_preprocess.csv')[aspect])\n",
    "    # ytest = label_encoder.fit_transform(pd.read_csv('dataset/test_preprocess.csv')[aspect])\n",
    "    # yvalid = pd.read_csv('dataset/valid_preprocess.csv')[aspect]\n",
    "    # ytest = pd.read_csv('dataset/test_preprocess.csv')[aspect]\n",
    "\n",
    "    if feature == \"bow\":\n",
    "        vectorizer = CountVectorizer()\n",
    "    elif feature == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    elif feature == \"fasttext\":\n",
    "        vectorizer = FastText.load(ft_path).wv\n",
    "    else:\n",
    "        raise Exception('Feature unknown. Use \"bow\" or \"tfidf\" or \"fasttext\"')\n",
    "\n",
    "    # transform\n",
    "    if feature == \"bow\" or feature == \"tfidf\":\n",
    "        vectorizer.fit(xtrain)\n",
    "        xtrain = vectorizer.transform(xtrain)\n",
    "        xvalid = vectorizer.transform(xvalid)\n",
    "        xtest = vectorizer.transform(xtest)\n",
    "    elif feature == \"fasttext\":\n",
    "        scaler = MinMaxScaler()\n",
    "        xtrain = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xtrain])\n",
    "        xvalid = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xvalid])\n",
    "        xtest = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xtest])\n",
    "\n",
    "     # all classifiers\n",
    "    classifier_model = {\"nb\" : MultinomialNB(),\n",
    "                        \"svm\": SVC(),\n",
    "                        \"lr\" : LogisticRegression(),\n",
    "                       }\n",
    "    # all params for grid-search\n",
    "    param_grids = {\"nb\" : {\"alpha\": np.linspace(0.001,1,50)},\n",
    "                   \"svm\": {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']},\n",
    "                   \"lr\" : {'C': np.linspace(0.001,10,100)},\n",
    "                  }\n",
    "\n",
    "    clf = hyperparam_tuning(xtrain, ytrain, xvalid, yvalid,\n",
    "                            classifier=classifier_model[classifier],\n",
    "                            param_grid=param_grids[classifier])\n",
    "\n",
    "    if feature == \"bow\" or feature == \"tfidf\":\n",
    "        pred = clf.predict(xtest.toarray())\n",
    "    else:\n",
    "        pred = clf.predict(xtest)\n",
    "        \n",
    "    f1score = f1_score(ytest, pred, average='macro')\n",
    "    accuracy = accuracy_score(ytest, pred)\n",
    "    \n",
    "    return f1score, accuracy, clf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, acc, _, _ = train_and_test(feature=\"fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: ac, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: air_panas, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: bau, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: general, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: kebersihan, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: linen, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: service, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: sunrise_meal, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: tv, f1: 0.6163453577764636, acc: 0.9440559440559441\n",
      "col: wifi, f1: 0.6163453577764636, acc: 0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "for col in colums:\n",
    "    f1, acc, _, _ = train_and_test(feature=\"bow\")\n",
    "    print(\"col: {}, f1: {}, acc: {}\".format(col, f1, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d81e0ab65a2d871dd04cd5480301015f0912bc0455ad9e82832e105402504a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
