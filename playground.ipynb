{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.4.3\n",
      "  Downloading pandas-1.4.3-cp39-cp39-macosx_11_0_arm64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.22.4\n",
      "  Using cached numpy-1.22.4-cp39-cp39-macosx_11_0_arm64.whl (12.8 MB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.9.3-cp39-cp39-macosx_12_0_arm64.whl (28.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.6 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk==3.7\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp39-cp39-macosx_12_0_arm64.whl (7.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.7 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gensim==4.2.0\n",
      "  Using cached gensim-4.2.0-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[K     |████████████████████████████████| 498 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in ./.absa-airy/lib/python3.9/site-packages (from pandas==1.4.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp39-cp39-macosx_11_0_arm64.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Using cached smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.absa-airy/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.4.3->-r requirements.txt (line 1)) (1.16.0)\n",
      "Installing collected packages: numpy, tqdm, threadpoolctl, smart-open, scipy, regex, pytz, joblib, click, scikit-learn, pandas, nltk, gensim\n",
      "Successfully installed click-8.1.3 gensim-4.2.0 joblib-1.2.0 nltk-3.7 numpy-1.22.4 pandas-1.4.3 pytz-2022.6 regex-2022.10.31 scikit-learn-1.1.3 scipy-1.9.3 smart-open-6.2.0 threadpoolctl-3.1.0 tqdm-4.64.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Users/fadhil/Desktop/Project/absa/.absa-airy/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import vstack\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colums = df_train.columns.to_list()\n",
    "colums.remove('review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac',\n",
       " 'air_panas',\n",
       " 'bau',\n",
       " 'general',\n",
       " 'kebersihan',\n",
       " 'linen',\n",
       " 'service',\n",
       " 'sunrise_meal',\n",
       " 'tv',\n",
       " 'wifi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ac, neutral: 1814, positive: 51, negative: 417, negative_positive: 1, total: 2283\n",
      "Columns: air_panas, neutral: 1922, positive: 26, negative: 335, negative_positive: 0, total: 2283\n",
      "Columns: bau, neutral: 1911, positive: 12, negative: 360, negative_positive: 0, total: 2283\n",
      "Columns: general, neutral: 2023, positive: 230, negative: 30, negative_positive: 0, total: 2283\n",
      "Columns: kebersihan, neutral: 1350, positive: 205, negative: 722, negative_positive: 6, total: 2283\n",
      "Columns: linen, neutral: 1613, positive: 63, negative: 606, negative_positive: 1, total: 2283\n",
      "Columns: service, neutral: 1649, positive: 247, negative: 386, negative_positive: 1, total: 2283\n",
      "Columns: sunrise_meal, neutral: 2108, positive: 75, negative: 100, negative_positive: 0, total: 2283\n",
      "Columns: tv, neutral: 2075, positive: 13, negative: 195, negative_positive: 0, total: 2283\n",
      "Columns: wifi, neutral: 1928, positive: 25, negative: 330, negative_positive: 0, total: 2283\n"
     ]
    }
   ],
   "source": [
    "for col in colums:\n",
    "    count = df_train[col].value_counts()\n",
    "\n",
    "    if not \"neg_pos\" in count:\n",
    "        count['neg_pos'] = 0\n",
    "        \n",
    "    print(\"Columns: {}, neutral: {}, positive: {}, negative: {}, negative_positive: {}, total: {}\".format(col, count['neut'], count['pos'], count['neg'], count['neg_pos'], count.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(xtrain, save_path='fasttext.ft'):\n",
    "    sentences = [word_tokenize(content.lower()) for content in xtrain]\n",
    "    vectorizer = FastText(sentences, vector_size=300, window=3, min_count=1, workers=4, epochs=1000, sg=0, hs=0)\n",
    "    vectorizer.save(save_path)\n",
    "    print('fasttext model saved at '+save_path)\n",
    "\n",
    "def norm_sent_vector(sentence, wv):\n",
    "    vecs = [wv[word.lower()] for word in word_tokenize(sentence)] \n",
    "    norm_vecs = [vec / np.linalg.norm(vecs) for vec in vecs if np.linalg.norm(vecs) > 0]\n",
    "    sent_vec = np.mean(norm_vecs, axis=0)\n",
    "    return sent_vec\n",
    "\n",
    "def hyperparam_tuning(xtrain, ytrain, xvalid, yvalid, classifier, param_grid):\n",
    "    # combine train and valid\n",
    "    x = vstack([xtrain, xvalid])\n",
    "    y = ytrain + yvalid\n",
    "    \n",
    "    # create predefined split\n",
    "    # -1 for all training and 0 for all validation\n",
    "    ps = PredefinedSplit([-1] * len(ytrain) + [0] * len(yvalid))\n",
    "    clf = GridSearchCV(classifier, param_grid, cv = ps)\n",
    "    clf = clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "def train_and_test(data_train, data_valid, data_test, feature=\"bow\", classifier=\"nb\", save_path=None, ft_path=\"fasttext.ft\"):\n",
    "    xtrain = data_train['review']\n",
    "    xvalid = data_valid['review']\n",
    "    xtest = data_test['review']\n",
    "\n",
    "    colums = data_train.columns.to_list()\n",
    "    colums.remove('review')\n",
    "\n",
    "    if feature == \"bow\":\n",
    "        vectorizer = CountVectorizer()\n",
    "    elif feature == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    elif feature == \"fasttext\":\n",
    "        vectorizer = FastText.load(ft_path).wv\n",
    "    else:\n",
    "        raise Exception('Feature unknown. Use \"bow\" or \"tfidf\" or \"fasttext\"')\n",
    "\n",
    "    # transform\n",
    "    if feature == \"bow\" or feature == \"tfidf\":\n",
    "        vectorizer.fit(xtrain)\n",
    "        xtrain = vectorizer.transform(xtrain)\n",
    "        xvalid = vectorizer.transform(xvalid)\n",
    "        xtest = vectorizer.transform(xtest)\n",
    "    elif feature == \"fasttext\":\n",
    "        scaler = MinMaxScaler()\n",
    "        xtrain = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xtrain])\n",
    "        xvalid = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xvalid])\n",
    "        xtest = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in xtest])\n",
    "\n",
    "    # all classifiers\n",
    "    classifier_model = {\"nb\" : MultinomialNB(),\n",
    "                        \"svm\": SVC(),\n",
    "                        \"lr\" : LogisticRegression(),\n",
    "                    }\n",
    "    # all params for grid-search\n",
    "    param_grids = {\"nb\" : {\"alpha\": np.linspace(0.001,1,50)},\n",
    "                \"svm\": {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']},\n",
    "                \"lr\" : {'C': np.linspace(0.001,10,100)},\n",
    "                }\n",
    "\n",
    "    categorical = {}\n",
    "    average_acc = 0\n",
    "    for col in colums:\n",
    "        ytrain = list(data_train[col])\n",
    "        yvalid = list(data_valid[col])\n",
    "        ytest = list(data_test[col])\n",
    "\n",
    "        clf = hyperparam_tuning(xtrain, ytrain, xvalid, yvalid,\n",
    "                                classifier=classifier_model[classifier],\n",
    "                                param_grid=param_grids[classifier])\n",
    "\n",
    "        if feature == \"bow\" or feature == \"tfidf\":\n",
    "            pred = clf.predict(xtest.toarray())\n",
    "        else:\n",
    "            pred = clf.predict(xtest)\n",
    "\n",
    "        f1 = f1_score(ytest, pred, average='macro')\n",
    "        acc = accuracy_score(ytest, pred) \n",
    "        average_acc += acc\n",
    "\n",
    "        categorical[col] = {'f1': f1, 'acc': acc}\n",
    "        \n",
    "        if save_path is not None:\n",
    "            filename = save_path+'/'+feature+'/'+col\n",
    "            os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "            with open(filename, 'wb') as fout:\n",
    "                pickle.dump((vectorizer, clf), fout)\n",
    "\n",
    "    average_acc = average_acc / len(colums)\n",
    "    return average_acc, categorical\n",
    "\n",
    "def predict(text, model_path, feature='bow'):\n",
    "\n",
    "    colums = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "    pred = {}\n",
    "    for col in colums:\n",
    "        with open(model_path+'/'+feature+'/'+col, 'rb') as f:\n",
    "            vectorizer, clf = pickle.load(f)\n",
    "\n",
    "            if feature == \"bow\" or feature == \"tfidf\":\n",
    "                x = vectorizer.transform([text])\n",
    "                pred[col] = clf.predict(x.toarray())[0]\n",
    "            elif feature == \"fasttext\":\n",
    "                scaler = MinMaxScaler()\n",
    "                x = scaler.fit_transform([norm_sent_vector(s, vectorizer) for s in [text]])\n",
    "                pred[col] = clf.predict(x)[0]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"dataset/train_preprocess.csv\")\n",
    "data_valid = pd.read_csv(\"dataset/valid_preprocess.csv\")\n",
    "data_test = pd.read_csv(\"dataset/test_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FastText Model for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext model saved at fasttext.ft\n"
     ]
    }
   ],
   "source": [
    "train_fasttext(data_train['review'], save_path='fasttext.ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Save Classifier for FastText Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8076923076923077\n",
      "Categorical Score:\n",
      "Aspect          F1-score                       Accuracy                      \n",
      "ac              0.3560398916848293             0.8286713286713286            \n",
      "air_panas       0.3075957313245449             0.8566433566433567            \n",
      "bau             0.3069182389937107             0.8531468531468531            \n",
      "general         0.3062381852551985             0.8496503496503497            \n",
      "kebersihan      0.31546001153117537            0.5804195804195804            \n",
      "linen           0.27191166321601107            0.6888111888111889            \n",
      "service         0.27991886409736305            0.7237762237762237            \n",
      "sunrise_meal    0.32                           0.9230769230769231            \n",
      "tv              0.31553100061387357            0.8986013986013986            \n",
      "wifi            0.3109452736318408             0.8741258741258742            \n"
     ]
    }
   ],
   "source": [
    "acc, categorical = train_and_test(data_train, data_valid, data_test, feature=\"fasttext\", save_path=\"model/train1\")\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(acc))\n",
    "print(\"Categorical Score:\")\n",
    "print(\"{:<15} {:<30} {:<30}\".format('Aspect', 'F1-score', 'Accuracy'))\n",
    "for k, v in categorical.items():\n",
    "    f1, acc = v.values()\n",
    "    print (\"{:<15} {:<30} {:<30}\".format(k, f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time Execute: 24.70976185798645 seconds ---\n",
      "ac              0.9545454545454546            \n",
      "air_panas       0.9545454545454546            \n",
      "bau             0.9545454545454546            \n",
      "general         0.9545454545454546            \n",
      "kebersihan      0.9545454545454546            \n",
      "linen           0.9545454545454546            \n",
      "service         0.9545454545454546            \n",
      "sunrise_meal    0.9545454545454546            \n",
      "tv              0.9545454545454546            \n",
      "wifi            0.9545454545454546            \n"
     ]
    }
   ],
   "source": [
    "text = \"lumayan nyaman,tp kebersihan kmr mandi perlu ditingkatkan lg biar gk ada kuning2 di sudutnya lbh bgs\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pred = predict(text, model_path=\"model/train1\", feature=\"fasttext\")\n",
    "\n",
    "print(\"--- Time Execute: %s seconds ---\" % (time.time() - start_time))\n",
    "for k, v in pred.items():\n",
    "    print (\"{:<15} {:<30}\".format(k, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Save Classifier for TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8692307692307694\n",
      "Categorical Score:\n",
      "Aspect          F1-score                       Accuracy                      \n",
      "ac              0.5065623023402909             0.8776223776223776            \n",
      "air_panas       0.47470777135517017            0.8986013986013986            \n",
      "bau             0.45163492388558946            0.8811188811188811            \n",
      "general         0.35138188771075957            0.8496503496503497            \n",
      "kebersihan      0.5238118995748172             0.7552447552447552            \n",
      "linen           0.5363641662295273             0.8426573426573427            \n",
      "service         0.6226459819873824             0.8181818181818182            \n",
      "sunrise_meal    0.3650273224043716             0.9265734265734266            \n",
      "tv              0.48686679174484054            0.9265734265734266            \n",
      "wifi            0.49487841113456876            0.916083916083916             \n"
     ]
    }
   ],
   "source": [
    "acc, categorical = train_and_test(data_train, data_valid, data_test, feature=\"tfidf\", save_path=\"model/train1\")\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(acc))\n",
    "print(\"Categorical Score:\")\n",
    "print(\"{:<15} {:<30} {:<30}\".format('Aspect', 'F1-score', 'Accuracy'))\n",
    "for k, v in categorical.items():\n",
    "    f1, acc = v.values()\n",
    "    print (\"{:<15} {:<30} {:<30}\".format(k, f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time Execute: 0.023123979568481445 seconds ---\n",
      "ac              0.916083916083916             \n",
      "air_panas       0.916083916083916             \n",
      "bau             0.916083916083916             \n",
      "general         0.916083916083916             \n",
      "kebersihan      0.916083916083916             \n",
      "linen           0.916083916083916             \n",
      "service         0.916083916083916             \n",
      "sunrise_meal    0.916083916083916             \n",
      "tv              0.916083916083916             \n",
      "wifi            0.916083916083916             \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pred = predict(text, model_path=\"model/train1\", feature=\"tfidf\")\n",
    "\n",
    "print(\"--- Time Execute: %s seconds ---\" % (time.time() - start_time))\n",
    "for k, v in pred.items():\n",
    "    print (\"{:<15} {:<30}\".format(k, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Save Classifier for BoW Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.9031468531468532\n",
      "Categorical Score:\n",
      "Aspect          F1-score                       Accuracy                      \n",
      "ac              0.6163453577764636             0.9440559440559441            \n",
      "air_panas       0.5462501384734685             0.9265734265734266            \n",
      "bau             0.5509052351157614             0.916083916083916             \n",
      "general         0.47007575757575754            0.8846153846153846            \n",
      "kebersihan      0.7713700755650752             0.8321678321678322            \n",
      "linen           0.6464597075510863             0.8776223776223776            \n",
      "service         0.7155265840442085             0.8496503496503497            \n",
      "sunrise_meal    0.3887486243283485             0.9125874125874126            \n",
      "tv              0.5333910533910534             0.9335664335664335            \n",
      "wifi            0.5976338028169015             0.9545454545454546            \n"
     ]
    }
   ],
   "source": [
    "acc, categorical = train_and_test(data_train, data_valid, data_test, feature=\"bow\", save_path=\"model/train1\")\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(acc))\n",
    "print(\"Categorical Score:\")\n",
    "print(\"{:<15} {:<30} {:<30}\".format('Aspect', 'F1-score', 'Accuracy'))\n",
    "for k, v in categorical.items():\n",
    "    f1, acc = v.values()\n",
    "    print (\"{:<15} {:<30} {:<30}\".format(k, f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time Execute: 0.013634920120239258 seconds ---\n",
      "ac              0.9545454545454546            \n",
      "air_panas       0.9545454545454546            \n",
      "bau             0.9545454545454546            \n",
      "general         0.9545454545454546            \n",
      "kebersihan      0.9545454545454546            \n",
      "linen           0.9545454545454546            \n",
      "service         0.9545454545454546            \n",
      "sunrise_meal    0.9545454545454546            \n",
      "tv              0.9545454545454546            \n",
      "wifi            0.9545454545454546            \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pred = predict(text, model_path=\"model/train1\", feature=\"bow\")\n",
    "\n",
    "print(\"--- Time Execute: %s seconds ---\" % (time.time() - start_time))\n",
    "for k, v in pred.items():\n",
    "    print (\"{:<15} {:<30}\".format(k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.absa-airy': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eaa4b1a4623afebaca11da0ac36861ace4a88b2b32b402c943c4e9cf7a4cac48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
